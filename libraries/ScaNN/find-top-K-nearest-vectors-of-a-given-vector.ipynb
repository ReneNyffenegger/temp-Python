{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0584440b-63e7-44d3-b423-6a6a75d27774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 20:42:38.777782: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-17 20:42:38.811080: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-17 20:42:38.812051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-17 20:42:39.419409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   https://medium.com/@DataPlayer/scalable-approximate-nearest-neighbour-search-using-googles-scann-and-facebook-s-faiss-3e84df25ba\n",
    "#\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scann\n",
    "import os\n",
    "\n",
    "# Generate a synthetic dataset of 1 million vectors\n",
    "NUM_VECTORS = 1000000\n",
    "VECTOR_DIM  = 128\n",
    "\n",
    "dataset = np.random.randn(NUM_VECTORS, VECTOR_DIM).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a86ec79-dbbc-4250-aa37-0831c78d09bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 22:07:58.988362: I scann/partitioning/partitioner_factory_base.cc:59] Size of sampled dataset for training partition: 249544\n",
      "2023-10-17 22:08:06.575689: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:84] PartitionerFactory ran in 7.587267959s.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Build a ScaNN index with L2 distance metric and 10 random projection hash tables\n",
    "#\n",
    "# scann_ops_pybind.builder is a method in the ScaNN library that is used to create a ScannBuilder object.\n",
    "#\n",
    "# The builder() method returns a ScannBuilder object,\n",
    "# which can be used to specify additional parameters such as\n",
    "#  - the number of projection hash tables to use and\n",
    "#  - the number of leaves in the hierarchical tree used to organize the data. \n",
    "\n",
    "# By default, ScaNN builds a k-means tree, where each leaf node represents a\n",
    "# cluster of vectors.\n",
    "# The .tree() method can be used to further split or merge these clusters to\n",
    "# optimize the search performance.\n",
    "\n",
    "searcher = scann.scann_ops_pybind.builder(\n",
    "    dataset,                             # numpy array containing the data points to be indexed\n",
    "    num_neighbors    =  10,              # the number of neighbors to search for\n",
    "    distance_measure = \"squared_l2\"      # the distance metric to use (e.g., 'dot_product' or 'squared_l2')\n",
    ").tree(                                  # .tree() is a method that can be used after(?) calling .build() to further refine the tree structure of the index. .tree() allows us to fine-tune the tree structure of the index to optimize the search performance for a given dataset and use case. It takes several arguments: \n",
    "    num_leaves           =   2000,       # num_leaves: the maximum number of leaves in the tree . This can be used to control the balance between search speed and memory usage. Increasing num_leaves will improve the search accuracy but also increase the memory usage.\n",
    "    num_leaves_to_search =    100,       #num_leaves_to_search: the number of leaves to search during the query phase\n",
    "    training_sample_size = 250000        # training_sample_size: the number of vectors to use for training the tree.\n",
    ").score_ah(                              # score_ah() is a method in ScaNN that sets the parameters for the asymmetric hash function used in the indexing process. It is called after .tree() because the tree structure is required to set these parameters.\n",
    "    2,                                   # num_neighbors sets the number of neighbors to consider when selecting the threshold for asymmetric hashing   \n",
    "    anisotropic_quantization_threshold = 0.2 # anisotropic_quantization_threshold controls how many different quantization levels to use for each dimension in the hash function (maller values generally resulting in better accuracy at the cost of higher indexing time and memory usage.)\n",
    ").reorder(\n",
    "    100\n",
    ").build()  # Finally, the ScannBuilder object's build() method is called to create the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2f78f2-6f2d-4972-a9e8-47d2c12b1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for the serialized index\n",
    "\n",
    "if not os.path.exists(\"scann_index\"):\n",
    "    os.makedirs(\"scann_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e986d45b-05cd-4b22-a3c1-3feb0b7dcc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index to disk\n",
    "\n",
    "searcher.serialize(\"scann_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc78fb-f72b-4daa-ba32-07fd9085218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the index from disk\n",
    "#searcher = scann.scann_ops_pybind.load_searcher(\"scann_index/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d64b2c-5c62-4aba-943d-a633a1274e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a query vector\n",
    "query_vector = np.random.randn(VECTOR_DIM).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c76ada-1a88-4e67-afd0-860496145c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 nearest neighbors of the query vector\n",
    "neighbors, distances = searcher.search(query_vector, final_num_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212b1752-c6ad-40a9-bc04-dc46f17179a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([732276, 981817, 598507, 510868, 730527,   2208, 122018, 973694,\n",
       "        741261, 231291], dtype=uint32),\n",
       " array([150.53412, 154.43344, 156.3534 , 156.4636 , 158.85886, 163.04324,\n",
       "        163.57863, 163.59833, 163.9052 , 164.5318 ], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neighbours is an array of indexes for nearest neighbors. distances is an array with their corresponding squared_L2 distnaces\n",
    "neighbors,distances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
